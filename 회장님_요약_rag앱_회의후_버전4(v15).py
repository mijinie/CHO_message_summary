import streamlit as st
import pandas as pd
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.schema import SystemMessage, HumanMessage
import openai
from io import BytesIO

# OpenAI í‚¤ ì„¸íŒ…
openai.api_key = st.secrets["OPENAI_API_KEY"]

# ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
vectorstore = FAISS.load_local(
    "ja-in_vectorstore",
    OpenAIEmbeddings(openai_api_key=openai.api_key),
    allow_dangerous_deserialization=True
)

# LLM ì¸ìŠ¤í„´ìŠ¤
llm = ChatOpenAI(model="gpt-4o", temperature=0.4)

# í•µì‹¬ í‚¤ì›Œë“œ ì—‘ì…€ ì—…ë¡œë“œ
st.title("íšŒì¥ë‹˜ ë‹µë³€ ìš”ì•½ â†’ ì¬êµ¬ì„± ìë™í™”")
keyword_file = st.file_uploader("ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"])
uploaded_file = st.file_uploader("ğŸ“„ Q&A ì—‘ì…€ ì—…ë¡œë“œ", type="xlsx")

if not uploaded_file or not keyword_file:
    st.stop()

# í•µì‹¬ í‚¤ì›Œë“œ ë¡œë”©
keyword_df = pd.read_excel(keyword_file)
core_keywords = keyword_df.iloc[:, 0].dropna().astype(str).tolist()

# --- 1ë‹¨ê³„: ìš”ì•½ í•¨ìˆ˜ ---
def generate_summary(question, background, answer):
    query = f"{question}\n{background}"
    docs = vectorstore.similarity_search(query, k=3)
    reference = "\n".join([doc.page_content for doc in docs])

    system_prompt = (
        "íšŒì¥ë‹˜ì˜ ì‹¤ì œ ë°œí™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •ëˆëœ ìš”ì•½ì„ ìƒì„±í•œë‹¤.\n"
        "- íšŒì¥ë‹˜ì˜ ì–´íˆ¬ì™€ ì›Œë”©ì€ ìµœëŒ€í•œ ìœ ì§€í•œë‹¤.\n"
        "- íë¦„ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ì •ëˆí•˜ë˜, ë‚´ìš©ì€ ì ˆëŒ€ë¡œ ì••ì¶•í•˜ì§€ ì•ŠëŠ”ë‹¤.\n"
        "- ì›ë¬¸ì—ì„œ ë§í•œ ëª¨ë“  í•µì‹¬ ë©”ì‹œì§€ì™€ ì„¤ëª…ì€ ê·¸ëŒ€ë¡œ ì‚´ì•„ ìˆì–´ì•¼ í•œë‹¤.\n"
        "- ì „ì²´ ë¶„ëŸ‰ì€ ì›ë¬¸ì˜ 90% ì´ìƒìœ¼ë¡œ ìœ ì§€í•´ì•¼ í•˜ë©°, ì›ë¬¸ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•œë‹¤.\n"
        "- 'ê´€ë ¨ ì°¸ê³ ìë£Œ'ëŠ” íšŒì¥ë‹˜ì˜ ì² í•™ì„ ë³´ì¡°ì ìœ¼ë¡œ ë°˜ì˜í•˜ë©°, ì‹¤ì œ ë°œí™”ì™€ ì¶©ëŒí•  ê²½ìš° ì›ë¬¸ì„ ìš°ì„ í•œë‹¤.\n"
        "- ë‹¨, íšŒì¥ë‹˜ì˜ ì² í•™ì— ì–´ê¸‹ë‚˜ê±°ë‚˜ ë§¥ë½ìƒ ì˜¤í•´ ì†Œì§€ê°€ í° í‘œí˜„ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ìì¸ì‚¬ìƒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ë³´ì™„í•œë‹¤.\n"
        "- ì¶œë ¥ì€ ëª¨ë‘ '~ë‹¤'ì²´ë¡œ í•œë‹¤."
        f"- ì£¼ì˜: ë‹¤ìŒì€ íšŒì¥ë‹˜ì˜ ì² í•™ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ìš©ì–´ì´ë‹¤. ì „ì‚¬ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¹„ìŠ·í•œ í‘œí˜„ìœ¼ë¡œ ì˜ëª» í‘œê¸°ë˜ì—ˆë”ë¼ë„, ë¬¸ë§¥ìƒ ê°™ìœ¼ë©´ ì˜¬ë°”ë¥¸ ìš©ì–´ë¡œ êµì •í•˜ë¼:\n{', '.join(core_keywords)}"
    )

    user_prompt = f"ì§ˆë¬¸:\n{question}\n\nì§ˆë¬¸ ë°°ê²½:\n{background}\n\në‹µë³€:\n{answer}\n\nê´€ë ¨ ì°¸ê³ ìë£Œ:\n{reference}"

    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ])
    return response.content

# --- 2ë‹¨ê³„: ì¬êµ¬ì„± í•¨ìˆ˜ ---
def regenerate_summary(original_summary, original_answer):
    regen_prompt = f"""
    ì•„ë˜ëŠ” íšŒì¥ë‹˜ì˜ ë‹µë³€ ìš”ì•½ì…ë‹ˆë‹¤. ë¬¸ì¥ ê°„ ì—°ê²° íë¦„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬í•˜ê³ , ì›ë¬¸ì—ì„œ ì¤‘ìš”í•œ ì˜ˆì‹œê°€ ìƒëµëœ ê²½ìš° ë‹¤ì‹œ ë°˜ì˜í•´ ì •ëˆí•´ì£¼ì„¸ìš”. 
    íšŒì¥ë‹˜ì˜ ë§íˆ¬ì™€ í†¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê³ , ë‚´ìš© ì¶•ì•½ ì—†ì´ ìµœëŒ€í•œ í’ë¶€í•˜ê²Œ ë³´ì™„í•˜ë˜ ì „ì²´ ë¶„ëŸ‰ì€ ìš”ì•½ë¬¸ì˜ 100~120% ì´ë‚´ë¡œ ë§ì¶°ì£¼ì„¸ìš”.
    ì¶œë ¥ì€ '~ë‹¤'ì²´ë¡œ í•´ì£¼ì„¸ìš”.

    ë‹¤ìŒ ìš©ì–´ë“¤ì´ ì¤‘ìš”í•œ ì² í•™ ìš©ì–´ì´ë‹ˆ ì „ì‚¬ ì˜¤ë¥˜ë¡œ ì˜ëª» í‘œê¸°ëœ ê²½ìš° ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ë°”ë¡œì¡ì•„ ì£¼ì„¸ìš”:
    {', '.join(core_keywords)}

    [ìš”ì•½ë¬¸]
    {original_summary}

    [ë‹µë³€ ì›ë¬¸]
    {original_answer}

    [ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]
    - ì£¼ì œ: ìì¸ì‚¬ìƒê³¼ ì„±ì°°
    - í•µì‹¬ ë©”ì‹œì§€: ë¦¬ë”ì˜ ì„±ì¥ì€ ë‚´ë©´ ì„±ì°°ê³¼ ì„¸ìƒì„ í–¥í•œ í™•ì¥ì  ì‹œì•¼ì—ì„œ ë¹„ë¡¯ëœë‹¤.
    - ë‚´ìš©:
    ë¦¬ë”ëŠ” ìì‹ ì„ ëŒì•„ë³´ê³ , ì„¸ìƒê³¼ì˜ ê´€ê³„ë¥¼ ê¹Šì´ ì´í•´í•´ì•¼ í•œë‹¤. ì´í•´ë¥¼ ìœ„í•´ì„œëŠ” 'ìì¸ì‚¬ìƒ'ì„ ì•„ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. ì´ë¥¼ í†µí•´ êµ¬ì„±ì›ì´ ìì‹ ì„ ë„˜ì–´ì„œ íƒ€ì¸ì„ í¬ìš©í•  ìˆ˜ ìˆê²Œ ë„ìš¸ ìˆ˜ ìˆìœ¼ë©°, ìì¸ì—ì„œ í•˜ëŠ” ë§ë“¤ì„ ì‹¤ì²œí•¨ìœ¼ë¡œì¨ ì„ í–‰í•˜ëŠ” ë¦¬ë”ê°€ ë  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, "ì„±ì¥ì€ ë™ì¼ì‹œì˜ í™•ì¥ ê³¼ì •ì´ë‹¤"ë¼ëŠ” ë§ì²˜ëŸ¼...

    ìœ„ í˜•ì‹ìœ¼ë¡œ ì¬êµ¬ì„±í•´ì¤˜.
    """
    chat = ChatOpenAI(model="gpt-4o", temperature=0.6)
    response = chat.invoke([HumanMessage(content=regen_prompt)])
    return response.content

# --- ì‹¤í–‰ ë¡œì§ ---
df = pd.read_excel(uploaded_file)

if {'ì‚¬ì „ì§ˆë¬¸', 'ì§ˆë¬¸ë°°ê²½', 'ë‹µë³€ì›ë¬¸'}.issubset(df.columns):
    with st.spinner("ìš”ì•½ ì¤‘..."):
        summaries = []
        progress = st.progress(0)
        for i, row in df.iterrows():
            summary = generate_summary(row['ì‚¬ì „ì§ˆë¬¸'], row['ì§ˆë¬¸ë°°ê²½'], row['ë‹µë³€ì›ë¬¸'])
            summaries.append(summary)
            progress.progress((i + 1) / len(df))
        df['ìë™ìš”ì•½'] = summaries
        st.success("âœ… ìš”ì•½ ì™„ë£Œ")

    with st.spinner("ì¬êµ¬ì„± ì¤‘..."):
        regens = []
        progress2 = st.progress(0)
        for i, row in df.iterrows():
            regen = regenerate_summary(row['ìë™ìš”ì•½'], row['ë‹µë³€ì›ë¬¸'])
            regens.append(regen)
            progress2.progress((i + 1) / len(df))
        df['ì¬êµ¬ì„±ìš”ì•½'] = regens
        st.success("âœ… ì¬êµ¬ì„± ì™„ë£Œ")

    st.dataframe(df[['ì‚¬ì „ì§ˆë¬¸', 'ìë™ìš”ì•½', 'ì¬êµ¬ì„±ìš”ì•½']])

    # ë‹¤ìš´ë¡œë“œ
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False)
    st.download_button("ğŸ“¥ ìµœì¢… ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", data=output.getvalue(), file_name="ìš”ì•½_ì¬êµ¬ì„±_ê²°ê³¼.xlsx")

else:
    st.error("í•„ìˆ˜ ì»¬ëŸ¼(ì‚¬ì „ì§ˆë¬¸, ì§ˆë¬¸ë°°ê²½, ë‹µë³€ì›ë¬¸)ì´ ëˆ„ë½ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
